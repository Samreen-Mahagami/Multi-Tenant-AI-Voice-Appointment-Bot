<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Bot - Browser Test Client</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 20px; 
            background: #f5f5f5;
        }
        .container { 
            background: white; 
            padding: 30px; 
            border-radius: 10px; 
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .status { 
            padding: 15px; 
            margin: 15px 0; 
            border-radius: 8px; 
            font-weight: bold;
        }
        .success { background-color: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
        .error { background-color: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
        .info { background-color: #d1ecf1; color: #0c5460; border: 1px solid #bee5eb; }
        .warning { background-color: #fff3cd; color: #856404; border: 1px solid #ffeaa7; }
        
        button { 
            padding: 12px 24px; 
            margin: 8px; 
            background: #007bff; 
            color: white; 
            border: none; 
            border-radius: 6px; 
            cursor: pointer; 
            font-size: 16px;
            transition: background 0.3s;
        }
        button:hover { background: #0056b3; }
        button:disabled { background: #6c757d; cursor: not-allowed; }
        
        .clinic-btn { 
            background: #28a745; 
            margin: 10px; 
            padding: 15px 25px;
            display: block;
            width: 100%;
            text-align: left;
        }
        .clinic-btn:hover { background: #218838; }
        
        .record-btn { 
            background: #dc3545; 
            font-size: 18px;
            padding: 15px 30px;
        }
        .record-btn:hover { background: #c82333; }
        .record-btn.recording { 
            background: #fd7e14; 
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .audio-controls { 
            margin: 20px 0; 
            text-align: center;
        }
        
        .conversation { 
            background: #f8f9fa; 
            padding: 20px; 
            border-radius: 8px; 
            margin: 20px 0; 
            max-height: 400px; 
            overflow-y: auto;
            border: 1px solid #dee2e6;
        }
        
        .message { 
            margin: 10px 0; 
            padding: 10px; 
            border-radius: 6px;
        }
        .user-message { 
            background: #e3f2fd; 
            border-left: 4px solid #2196f3;
        }
        .bot-message { 
            background: #f3e5f5; 
            border-left: 4px solid #9c27b0;
        }
        
        .config-panel { 
            background: #f8f9fa; 
            padding: 20px; 
            border-radius: 8px; 
            margin: 20px 0;
            border: 1px solid #dee2e6;
        }
        
        .volume-meter { 
            width: 100%; 
            height: 20px; 
            background: #e9ecef; 
            border-radius: 10px; 
            overflow: hidden; 
            margin: 10px 0;
        }
        .volume-bar { 
            height: 100%; 
            background: linear-gradient(90deg, #28a745, #ffc107, #dc3545); 
            width: 0%; 
            transition: width 0.1s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéØ AI Voice Bot - Browser Test Client</h1>
        
        <div id="status" class="status info">
            <strong>üîä Status:</strong> Ready to start voice testing
        </div>

        <div class="config-panel">
            <h3>üè• Select Clinic to Test:</h3>
            <button class="clinic-btn" onclick="selectClinic('1001', 'Downtown Medical Center')" id="clinic1001">
                <strong>1001 - Downtown Medical Center</strong><br>
                <small>Voice: Joanna (Neural) - "Hello! Welcome to Downtown Medical Center. How can I help you today?"</small>
            </button>
            <button class="clinic-btn" onclick="selectClinic('1002', 'Westside Family Practice')" id="clinic1002">
                <strong>1002 - Westside Family Practice</strong><br>
                <small>Voice: Matthew (Neural) - "Hi there! This is Westside Family Practice. What can I do for you?"</small>
            </button>
            <button class="clinic-btn" onclick="selectClinic('1003', 'Pediatric Care Clinic')" id="clinic1003">
                <strong>1003 - Pediatric Care Clinic</strong><br>
                <small>Voice: Amy (Neural) - "Hello! You've reached Pediatric Care Clinic. How may I assist you today?"</small>
            </button>
        </div>

        <div class="audio-controls">
            <h3>üé§ Voice Controls:</h3>
            <button id="recordBtn" class="record-btn" onclick="toggleRecording()" disabled>
                üé§ Click to Start Talking
            </button>
            <div class="volume-meter">
                <div id="volumeBar" class="volume-bar"></div>
            </div>
            <p><small>üí° Click and hold to speak, release to send to AI</small></p>
        </div>

        <div class="conversation" id="conversation">
            <div class="message bot-message">
                <strong>ü§ñ AI Bot:</strong> Please select a clinic above to start your voice conversation!
            </div>
        </div>

        <div class="config-panel">
            <h3>üîß Technical Info:</h3>
            <p><strong>Media Gateway:</strong> <span id="gatewayStatus">Not connected</span></p>
            <p><strong>Selected Clinic:</strong> <span id="selectedClinic">None</span></p>
            <p><strong>Call ID:</strong> <span id="callId">-</span></p>
            <p><strong>Audio Format:</strong> 16kHz, 16-bit, Mono (AWS Transcribe compatible)</p>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let websocket = null;
        let selectedDID = null;
        let selectedClinicName = null;
        let callId = null;
        let isRecording = false;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let speechSynthesis = window.speechSynthesis;
        let currentVoice = null;
        let heartbeatInterval = null;
        let recognition = null;
        let isListening = false;

        function log(message, type = 'bot') {
            const conversation = document.getElementById('conversation');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}-message`;
            
            const timestamp = new Date().toLocaleTimeString();
            const icon = type === 'user' ? 'üë§' : 'ü§ñ';
            const label = type === 'user' ? 'You' : 'AI Bot';
            
            messageDiv.innerHTML = `<strong>${icon} ${label}:</strong> ${message} <small style="color: #6c757d;">[${timestamp}]</small>`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function updateStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.className = `status ${type}`;
            status.innerHTML = `<strong>üîä Status:</strong> ${message}`;
        }

        function selectClinic(did, clinicName) {
            console.log('selectClinic called with:', did, clinicName);
            selectedDID = did;
            selectedClinicName = clinicName;
            callId = `call-${Date.now()}`;
            
            document.getElementById('selectedClinic').textContent = `${did} - ${clinicName}`;
            document.getElementById('callId').textContent = callId;
            
            // Set voice based on clinic
            setVoiceForClinic(did);
            
            // Enable recording
            document.getElementById('recordBtn').disabled = false;
            
            // Connect to Media Gateway
            connectToMediaGateway();
            
            log(`Connected to ${clinicName}. You can now start talking!`);
            updateStatus(`Connected to ${clinicName} - Ready for voice input`, 'success');
        }

        function setVoiceForClinic(did) {
            const voices = speechSynthesis.getVoices();
            
            // Voice mapping for each clinic
            const voiceMap = {
                '1001': { name: 'Joanna', gender: 'female', lang: 'en-US' }, // Downtown Medical
                '1002': { name: 'Matthew', gender: 'male', lang: 'en-US' },   // Westside Family
                '1003': { name: 'Amy', gender: 'female', lang: 'en-GB' }      // Pediatric Care
            };
            
            const targetVoice = voiceMap[did] || voiceMap['1001'];
            
            // Find best matching voice
            currentVoice = voices.find(voice => 
                voice.lang.startsWith(targetVoice.lang) && 
                voice.name.toLowerCase().includes(targetVoice.gender === 'female' ? 'female' : 'male')
            ) || voices.find(voice => 
                voice.lang.startsWith('en') && 
                voice.name.toLowerCase().includes(targetVoice.gender === 'female' ? 'female' : 'male')
            ) || voices.find(voice => voice.lang.startsWith('en')) || voices[0];
            
            log(`üéµ Voice set to: ${currentVoice ? currentVoice.name : 'Default'} for ${selectedClinicName}`);
        }

        function connectToMediaGateway() {
            const wsUrl = `ws://localhost:8080/ws/audio?callId=${callId}&did=${selectedDID}`;
            
            websocket = new WebSocket(wsUrl);
            
            websocket.onopen = function() {
                document.getElementById('gatewayStatus').textContent = 'Connected ‚úÖ';
                log('Connected to Media Gateway - Voice processing ready!');
                
                // Start heartbeat to keep connection alive
                heartbeatInterval = setInterval(() => {
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        websocket.send(JSON.stringify({ type: 'heartbeat' }));
                    }
                }, 15000); // Send heartbeat every 15 seconds
            };
            
            websocket.onmessage = function(event) {
                if (event.data instanceof Blob) {
                    // Received audio response from bot (not used in current implementation)
                    playAudioResponse(event.data);
                } else {
                    // Text message from gateway
                    const data = JSON.parse(event.data);
                    if (data.type === 'transcript') {
                        log(`Transcribed: "${data.text}"`, 'user');
                    } else if (data.type === 'response') {
                        log(data.text);
                        // Speak the AI response using browser TTS
                        speakText(data.text);
                    } else if (data.type === 'audio_start') {
                        log(`üîä AI is speaking...`);
                        updateStatus('AI is speaking...', 'info');
                    } else if (data.type === 'audio_end') {
                        log('‚úÖ AI finished speaking');
                        updateStatus('Ready for next voice input', 'success');
                    }
                }
            };
            
            websocket.onerror = function(error) {
                console.error('WebSocket error:', error);
                document.getElementById('gatewayStatus').textContent = 'Error ‚ùå';
                updateStatus('Connection error - reconnecting...', 'error');
                if (heartbeatInterval) {
                    clearInterval(heartbeatInterval);
                }
                
                // Auto-reconnect after 2 seconds on error
                if (selectedDID) {
                    setTimeout(() => {
                        log('üîÑ Reconnecting after error...');
                        connectToMediaGateway();
                    }, 2000);
                }
            };
            
            websocket.onclose = function() {
                document.getElementById('gatewayStatus').textContent = 'Disconnected ‚ùå';
                updateStatus('Disconnected from Media Gateway - reconnecting...', 'warning');
                if (heartbeatInterval) {
                    clearInterval(heartbeatInterval);
                }
                
                // Auto-reconnect after 1 second if we have a selected clinic
                if (selectedDID) {
                    setTimeout(() => {
                        log('üîÑ Auto-reconnecting to Media Gateway...');
                        connectToMediaGateway();
                    }, 1000);
                }
            };
        }

        let recognition = null;
        let isListening = false;

        function initializeSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
            } else if ('SpeechRecognition' in window) {
                recognition = new SpeechRecognition();
            } else {
                log('‚ùå Speech recognition not supported in this browser');
                updateStatus('Speech recognition not supported - try Chrome or Edge', 'error');
                return false;
            }

            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = function() {
                isListening = true;
                log('üé§ Listening for speech...');
                updateStatus('üé§ Listening... speak now!', 'warning');
            };

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                log(`Transcribed: "${transcript}"`, 'user');
                
                // Send transcript to Media Gateway
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    const message = {
                        type: 'transcript',
                        text: transcript
                    };
                    websocket.send(JSON.stringify(message));
                }
            };

            recognition.onerror = function(event) {
                log(`‚ùå Speech recognition error: ${event.error}`);
                updateStatus(`Speech recognition error: ${event.error}`, 'error');
                isListening = false;
            };

            recognition.onend = function() {
                isListening = false;
                updateStatus('Processing your request...', 'info');
            };

            return true;
        }

        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
            } else if ('SpeechRecognition' in window) {
                recognition = new SpeechRecognition();
            } else {
                log('‚ùå Speech recognition not supported - using audio recording fallback');
                return false;
            }

            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';

            recognition.onstart = function() {
                isListening = true;
                updateStatus('üé§ Listening... speak now!', 'warning');
            };

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                log(`Transcribed: "${transcript}"`, 'user');
                
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(JSON.stringify({
                        type: 'transcript',
                        text: transcript
                    }));
                }
            };

            recognition.onerror = function(event) {
                log(`‚ùå Speech recognition error: ${event.error}`);
                isListening = false;
            };

            recognition.onend = function() {
                isListening = false;
                updateStatus('Processing your request...', 'info');
            };

            return true;
        }

        async function toggleRecording() {
            if (!selectedDID) {
                updateStatus('Please select a clinic first', 'warning');
                return;
            }

            // Use speech recognition for better performance
            if (recognition || initSpeechRecognition()) {
                if (isListening) {
                    recognition.stop();
                    document.getElementById('recordBtn').textContent = 'üé§ Click to Start Talking';
                    document.getElementById('recordBtn').className = 'record-btn';
                } else {
                    recognition.start();
                    document.getElementById('recordBtn').textContent = 'üé§ Listening... (Click to Stop)';
                    document.getElementById('recordBtn').className = 'record-btn recording';
                }
            } else {
                // Fallback to audio recording if speech recognition not available
                if (isRecording) {
                    stopRecording();
                } else {
                    await startRecording();
                }
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Setup audio context for volume monitoring
                audioContext = new AudioContext({ sampleRate: 16000 });
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Start volume monitoring
                function updateVolume() {
                    if (isRecording) {
                        analyser.getByteFrequencyData(dataArray);
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        const percentage = (average / 255) * 100;
                        document.getElementById('volumeBar').style.width = percentage + '%';
                        requestAnimationFrame(updateVolume);
                    }
                }
                updateVolume();

                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = function() {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    sendAudioToGateway(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = 'üé§ Recording... (Release to Send)';
                recordBtn.className = 'record-btn recording';
                
                updateStatus('Recording your voice...', 'warning');
                
            } catch (error) {
                console.error('Error starting recording:', error);
                updateStatus('Microphone access denied or not available', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop all tracks
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up audio context
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = 'üé§ Click to Start Talking';
                recordBtn.className = 'record-btn';
                
                document.getElementById('volumeBar').style.width = '0%';
                
                updateStatus('Processing your voice...', 'info');
            }
        }

        function sendAudioToGateway(audioBlob) {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                log('Sending audio to AI for processing...', 'user');
                websocket.send(audioBlob);
            } else {
                updateStatus('Not connected to Media Gateway', 'error');
            }
        }

        function speakText(text) {
            // Stop any current speech
            speechSynthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            
            // Configure voice
            if (currentVoice) {
                utterance.voice = currentVoice;
            }
            
            // Voice settings
            utterance.rate = 0.9;    // Slightly slower for clarity
            utterance.pitch = 1.0;   // Normal pitch
            utterance.volume = 0.8;  // Slightly quieter
            
            // Event handlers
            utterance.onstart = function() {
                log('üîä AI is speaking...');
                updateStatus('üîä AI is speaking...', 'info');
            };
            
            utterance.onend = function() {
                log('‚úÖ AI finished speaking');
                updateStatus('Ready for next voice input', 'success');
            };
            
            utterance.onerror = function(event) {
                log('‚ùå Speech synthesis error: ' + event.error);
                updateStatus('Speech error - check browser TTS support', 'error');
            };
            
            // Speak the text
            speechSynthesis.speak(utterance);
        }

        function playAudioResponse(audioBlob) {
            // Fallback for binary audio (not used in current implementation)
            const audio = new Audio();
            const audioUrl = URL.createObjectURL(audioBlob);
            audio.src = audioUrl;
            
            audio.onloadeddata = function() {
                log('Playing AI response...');
                audio.play();
            };
            
            audio.onended = function() {
                URL.revokeObjectURL(audioUrl);
                updateStatus('Ready for next voice input', 'success');
            };
            
            audio.onerror = function() {
                log('Error playing audio response');
                updateStatus('Audio playback error', 'error');
            };
        }

        // Initialize
        updateStatus('Select a clinic to start voice testing', 'info');
        log('üöÄ Browser Voice Client initialized. Select a clinic above to begin!');
        
        // Load voices when available
        speechSynthesis.onvoiceschanged = function() {
            const voices = speechSynthesis.getVoices();
            log(`üéµ Loaded ${voices.length} voices for text-to-speech`);
        };
        
        // Add keyboard shortcuts
        document.addEventListener('keydown', function(event) {
            if (event.code === 'Space' && selectedDID && !isRecording) {
                event.preventDefault();
                startRecording();
            }
        });
        
        document.addEventListener('keyup', function(event) {
            if (event.code === 'Space' && isRecording) {
                event.preventDefault();
                stopRecording();
            }
        });
    </script>
</body>
</html>