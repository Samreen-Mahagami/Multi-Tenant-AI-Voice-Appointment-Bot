<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Bot - Real Voice Test</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 20px; 
            background: #f5f5f5;
        }
        .container { 
            background: white; 
            padding: 30px; 
            border-radius: 10px; 
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .status { 
            padding: 15px; 
            margin: 15px 0; 
            border-radius: 8px; 
            font-weight: bold;
        }
        .success { background-color: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
        .error { background-color: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
        .info { background-color: #d1ecf1; color: #0c5460; border: 1px solid #bee5eb; }
        .warning { background-color: #fff3cd; color: #856404; border: 1px solid #ffeaa7; }
        
        button { 
            padding: 12px 24px; 
            margin: 8px; 
            background: #007bff; 
            color: white; 
            border: none; 
            border-radius: 6px; 
            cursor: pointer; 
            font-size: 16px;
            transition: background 0.3s;
        }
        button:hover { background: #0056b3; }
        button:disabled { background: #6c757d; cursor: not-allowed; }
        
        .clinic-btn { 
            background: #28a745; 
            margin: 10px; 
            padding: 15px 25px;
            display: block;
            width: 100%;
            text-align: left;
        }
        .clinic-btn:hover { background: #218838; }
        
        .record-btn { 
            background: #dc3545; 
            font-size: 18px;
            padding: 15px 30px;
        }
        .record-btn:hover { background: #c82333; }
        .record-btn.recording { 
            background: #fd7e14; 
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .audio-controls { 
            margin: 20px 0; 
            text-align: center;
        }
        
        .conversation { 
            background: #f8f9fa; 
            padding: 20px; 
            border-radius: 8px; 
            margin: 20px 0; 
            max-height: 400px; 
            overflow-y: auto;
            border: 1px solid #dee2e6;
        }
        
        .message { 
            margin: 10px 0; 
            padding: 10px; 
            border-radius: 6px;
        }
        .user-message { 
            background: #e3f2fd; 
            border-left: 4px solid #2196f3;
        }
        .bot-message { 
            background: #f3e5f5; 
            border-left: 4px solid #9c27b0;
        }
        .speaking { 
            background: #fff3cd; 
            border-left: 4px solid #ffc107;
            animation: pulse 2s infinite;
        }
        
        .config-panel { 
            background: #f8f9fa; 
            padding: 20px; 
            border-radius: 8px; 
            margin: 20px 0;
            border: 1px solid #dee2e6;
        }
        
        .volume-meter { 
            width: 100%; 
            height: 20px; 
            background: #e9ecef; 
            border-radius: 10px; 
            overflow: hidden; 
            margin: 10px 0;
        }
        .volume-bar { 
            height: 100%; 
            background: linear-gradient(90deg, #28a745, #ffc107, #dc3545); 
            width: 0%; 
            transition: width 0.1s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéØ AI Voice Bot - Real Voice Test</h1>
        
        <div id="status" class="status info">
            <strong>üîä Status:</strong> Ready to start voice testing
        </div>

        <div class="config-panel">
            <h3>üè• Select Clinic to Test:</h3>
            <button class="clinic-btn" onclick="selectClinic('1001', 'Downtown Medical Center')" id="clinic1001">
                <strong>1001 - Downtown Medical Center</strong><br>
                <small>Voice: Female (Joanna-style) - "Hello! Welcome to Downtown Medical Center. How can I help you today?"</small>
            </button>
            <button class="clinic-btn" onclick="selectClinic('1002', 'Westside Family Practice')" id="clinic1002">
                <strong>1002 - Westside Family Practice</strong><br>
                <small>Voice: Male (Matthew-style) - "Hi there! This is Westside Family Practice. What can I do for you?"</small>
            </button>
            <button class="clinic-btn" onclick="selectClinic('1003', 'Pediatric Care Clinic')" id="clinic1003">
                <strong>1003 - Pediatric Care Clinic</strong><br>
                <small>Voice: Female (Amy-style) - "Hello! You've reached Pediatric Care Clinic. How may I assist you today?"</small>
            </button>
        </div>

        <div class="audio-controls">
            <h3>üé§ Voice Controls:</h3>
            <button id="recordBtn" class="record-btn" onclick="toggleRecording()" disabled>
                üé§ Click to Start Talking
            </button>
            <div class="volume-meter">
                <div id="volumeBar" class="volume-bar"></div>
            </div>
            <p><small>üí° Click and hold to speak, release to send to AI</small></p>
        </div>

        <div class="conversation" id="conversation">
            <div class="message bot-message">
                <strong>ü§ñ AI Bot:</strong> Please select a clinic above to start your voice conversation!
            </div>
        </div>

        <div class="config-panel">
            <h3>üîß Technical Info:</h3>
            <p><strong>Media Gateway:</strong> <span id="gatewayStatus">Not connected</span></p>
            <p><strong>Selected Clinic:</strong> <span id="selectedClinic">None</span></p>
            <p><strong>Call ID:</strong> <span id="callId">-</span></p>
            <p><strong>Voice Engine:</strong> Browser Text-to-Speech (Web Speech API)</p>
            <p><strong>Audio Format:</strong> 16kHz, 16-bit, Mono (AWS Transcribe compatible)</p>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let websocket = null;
        let selectedDID = null;
        let selectedClinicName = null;
        let callId = null;
        let isRecording = false;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let speechSynthesis = window.speechSynthesis;
        let currentVoice = null;
        let isSpeaking = false;

        function log(message, type = 'bot') {
            const conversation = document.getElementById('conversation');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}-message`;
            
            const timestamp = new Date().toLocaleTimeString();
            const icon = type === 'user' ? 'üë§' : type === 'speaking' ? 'üîä' : 'ü§ñ';
            const label = type === 'user' ? 'You' : type === 'speaking' ? 'AI Speaking' : 'AI Bot';
            
            messageDiv.innerHTML = `<strong>${icon} ${label}:</strong> ${message} <small style="color: #6c757d;">[${timestamp}]</small>`;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
            
            return messageDiv;
        }

        function updateStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.className = `status ${type}`;
            status.innerHTML = `<strong>üîä Status:</strong> ${message}`;
        }

        function selectClinic(did, clinicName) {
            selectedDID = did;
            selectedClinicName = clinicName;
            callId = `call-${Date.now()}`;
            
            document.getElementById('selectedClinic').textContent = `${did} - ${clinicName}`;
            document.getElementById('callId').textContent = callId;
            
            // Set voice based on clinic
            setVoiceForClinic(did);
            
            // Enable recording
            document.getElementById('recordBtn').disabled = false;
            
            // Connect to Media Gateway
            connectToMediaGateway();
            
            log(`Connected to ${clinicName}. You can now start talking!`);
            updateStatus(`Connected to ${clinicName} - Ready for voice input`, 'success');
        }

        function setVoiceForClinic(did) {
            // Wait for voices to load
            if (speechSynthesis.getVoices().length === 0) {
                speechSynthesis.addEventListener('voiceschanged', () => setVoiceForClinic(did));
                return;
            }
            
            const voices = speechSynthesis.getVoices();
            
            // Voice mapping for each clinic
            const voiceMap = {
                '1001': { gender: 'female', lang: 'en-US', rate: 0.9, pitch: 1.0 }, // Downtown Medical
                '1002': { gender: 'male', lang: 'en-US', rate: 0.8, pitch: 0.8 },   // Westside Family
                '1003': { gender: 'female', lang: 'en-GB', rate: 1.0, pitch: 1.1 }  // Pediatric Care
            };
            
            const targetVoice = voiceMap[did] || voiceMap['1001'];
            
            // Find best matching voice
            currentVoice = voices.find(voice => 
                voice.lang.startsWith(targetVoice.lang) && 
                (targetVoice.gender === 'female' ? 
                    (voice.name.toLowerCase().includes('female') || voice.name.toLowerCase().includes('woman') || !voice.name.toLowerCase().includes('male')) :
                    (voice.name.toLowerCase().includes('male') || voice.name.toLowerCase().includes('man'))
                )
            ) || voices.find(voice => voice.lang.startsWith('en')) || voices[0];
            
            log(`üéµ Voice set to: ${currentVoice ? currentVoice.name : 'Default'} (${targetVoice.gender}) for ${selectedClinicName}`);
        }

        function connectToMediaGateway() {
            const wsUrl = `ws://localhost:8080/ws/audio?callId=${callId}&did=${selectedDID}`;
            
            websocket = new WebSocket(wsUrl);
            
            websocket.onopen = function() {
                document.getElementById('gatewayStatus').textContent = 'Connected ‚úÖ';
                log('Connected to Media Gateway - Voice processing ready!');
            };
            
            websocket.onmessage = function(event) {
                if (event.data instanceof Blob) {
                    // Received audio response from bot (not used in current implementation)
                    log('Received audio blob from server (not implemented)');
                } else {
                    // Text message from gateway
                    const data = JSON.parse(event.data);
                    if (data.type === 'transcript') {
                        log(`Transcribed: "${data.text}"`, 'user');
                    } else if (data.type === 'response') {
                        log(data.text);
                        // Speak the AI response using browser TTS
                        speakText(data.text);
                    } else if (data.type === 'audio_start') {
                        log(`üîä AI is speaking...`, 'speaking');
                        updateStatus('AI is speaking...', 'info');
                    } else if (data.type === 'audio_end') {
                        updateStatus('Ready for next voice input', 'success');
                    }
                }
            };
            
            websocket.onerror = function(error) {
                console.error('WebSocket error:', error);
                document.getElementById('gatewayStatus').textContent = 'Error ‚ùå';
                updateStatus('Connection error - check if services are running', 'error');
            };
            
            websocket.onclose = function() {
                document.getElementById('gatewayStatus').textContent = 'Disconnected ‚ùå';
                updateStatus('Disconnected from Media Gateway', 'warning');
            };
        }

        function speakText(text) {
            if (isSpeaking) {
                speechSynthesis.cancel(); // Stop current speech
            }
            
            const utterance = new SpeechSynthesisUtterance(text);
            
            if (currentVoice) {
                utterance.voice = currentVoice;
            }
            
            // Set voice parameters based on clinic
            const voiceMap = {
                '1001': { rate: 0.9, pitch: 1.0, volume: 0.8 }, // Downtown Medical
                '1002': { rate: 0.8, pitch: 0.8, volume: 0.9 }, // Westside Family
                '1003': { rate: 1.0, pitch: 1.1, volume: 0.8 }  // Pediatric Care
            };
            
            const voiceSettings = voiceMap[selectedDID] || voiceMap['1001'];
            utterance.rate = voiceSettings.rate;
            utterance.pitch = voiceSettings.pitch;
            utterance.volume = voiceSettings.volume;
            
            utterance.onstart = function() {
                isSpeaking = true;
                updateStatus('üîä AI is speaking...', 'warning');
                log(`üîä Speaking: "${text}"`, 'speaking');
            };
            
            utterance.onend = function() {
                isSpeaking = false;
                updateStatus('Ready for next voice input', 'success');
                log('‚úÖ AI finished speaking');
            };
            
            utterance.onerror = function(event) {
                isSpeaking = false;
                updateStatus('Speech synthesis error', 'error');
                log(`‚ùå Speech error: ${event.error}`);
            };
            
            speechSynthesis.speak(utterance);
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Stop any current speech
                if (isSpeaking) {
                    speechSynthesis.cancel();
                    isSpeaking = false;
                }
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Setup audio context for volume monitoring
                audioContext = new AudioContext({ sampleRate: 16000 });
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                // Start volume monitoring
                function updateVolume() {
                    if (isRecording) {
                        analyser.getByteFrequencyData(dataArray);
                        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
                        const percentage = (average / 255) * 100;
                        document.getElementById('volumeBar').style.width = percentage + '%';
                        requestAnimationFrame(updateVolume);
                    }
                }
                updateVolume();

                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = function() {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    sendAudioToGateway(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = 'üé§ Recording... (Release to Send)';
                recordBtn.className = 'record-btn recording';
                
                updateStatus('Recording your voice...', 'warning');
                
            } catch (error) {
                console.error('Error starting recording:', error);
                updateStatus('Microphone access denied or not available', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                
                // Stop all tracks
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clean up audio context
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                
                const recordBtn = document.getElementById('recordBtn');
                recordBtn.textContent = 'üé§ Click to Start Talking';
                recordBtn.className = 'record-btn';
                
                document.getElementById('volumeBar').style.width = '0%';
                
                updateStatus('Processing your voice...', 'info');
            }
        }

        function sendAudioToGateway(audioBlob) {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                log('Sending audio to AI for processing...', 'user');
                websocket.send(audioBlob);
            } else {
                updateStatus('Not connected to Media Gateway', 'error');
            }
        }

        // Initialize
        updateStatus('Select a clinic to start voice testing', 'info');
        log('üöÄ Real Voice Client initialized. Select a clinic above to begin!');
        
        // Load voices
        if (speechSynthesis.getVoices().length === 0) {
            speechSynthesis.addEventListener('voiceschanged', function() {
                log(`üéµ ${speechSynthesis.getVoices().length} voices loaded`);
            });
        }
        
        // Add keyboard shortcuts
        document.addEventListener('keydown', function(event) {
            if (event.code === 'Space' && selectedDID && !isRecording && !isSpeaking) {
                event.preventDefault();
                startRecording();
            }
        });
        
        document.addEventListener('keyup', function(event) {
            if (event.code === 'Space' && isRecording) {
                event.preventDefault();
                stopRecording();
            }
        });
    </script>
</body>
</html>